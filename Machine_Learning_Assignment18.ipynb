{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5fa8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is the difference between supervised and unsupervised learning? Give some examples to\n",
    "illustrate your point.\n",
    "\n",
    "supervised learning uses labeled input and output data, while an unsupervised learning algorithm does not. In supervised learning, the algorithm learns from the training dataset by iteratively making predictions on the data and adjusting for the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adc24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Mention a few unsupervised learning applications.\n",
    "\n",
    "the main applications of unsupervised learning include clustering, visualization, dimensionality reduction, finding association rules, and anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. What are the three main types of clustering methods? \n",
    "Centroid-based Clustering.\n",
    "Density-based Clustering.\n",
    "Distribution-based Clustering.\n",
    "Hierarchical Clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1461245",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Explain how the k-means algorithm determines the consistency of clustering.\n",
    "In k-means clustering, the number of clusters that you want to divide your data points into i.e., the value of K has to be pre-determined whereas in Hierarchical clustering data is automatically formed into a tree shape form (dendrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c801b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. With a simple illustration, explain the key difference between the k-means and k-medoids\n",
    "algorithms.\n",
    "\n",
    "K -means attempts to minimize the total squared error, while k -medoids minimizes the sum of dissimilarities between points labeled to be in a cluster and a point designated as the center of that cluster. In contrast to the k-means algorithm, k-medoids chooses datapoints as centers (medoids or exemplars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42756ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. What is a dendrogram, and how does it work? Explain how to do it.\n",
    "A dendrogram is a diagram that shows the attribute distances between each pair of sequentially merged classes. To avoid crossing lines, the diagram is graphically arranged so that members of each pair of classes to be merged are neighbors in the diagram. The Dendrogram tool uses a hierarchical clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1977b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. What exactly is SSE? What role does it play in the k-means algorithm?\n",
    "\n",
    "SSE is defined as the sum of the squared distance between centroid and each member of the cluster. Then plot a K against SSE graph. We will observe that as K increases SSE decreases as disortation will be small. So the idea of this algorithm is to choose the value of K at which the graph decrease abruptly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. With a step-by-step algorithm, explain the k-means procedure.\n",
    "\n",
    "Step 1: Choose the number of clusters k. ...\n",
    "Step 2: Select k random points from the data as centroids. ...\n",
    "Step 3: Assign all the points to the closest cluster centroid. ...\n",
    "Step 4: Recompute the centroids of newly formed clusters. ...\n",
    "Step 5: Repeat steps 3 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55afa50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. In the sense of hierarchical clustering, define the terms single link and complete link.\n",
    "\n",
    "In single-link (or single linkage) hierarchical clustering, we merge in each step the two clusters whose two closest members have the smallest distance (or: the two clusters with the smallest minimum pairwise distance). Complete-link clustering can also be described using the concept of clique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce57fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. How does the apriori concept aid in the reduction of measurement overhead in a business\n",
    "basket analysis? Give an example to demonstrate your point.\n",
    "\n",
    "To perform a Market Basket Analysis and identify potential rules, a data mining algorithm called the 'Apriori algorithm' is commonly used, which works in two steps: Systematically identify itemsets that occur frequently in the data set with a support greater than a pre-specified threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e695d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
